// Module included in the following assemblies:
//
// * backup_and_restore/application_backup_and_restore/backing_up_and_restoring/backing-up-applications.adoc

:_content-type: PROCEDURE
[id="oadp-using-data-mover-with-ceph-fs_{context}"]
= Using Data Mover for CSI snapshots with Ceph FS storage

You can use the CephFS ROX shallow copy feature to expose CephFS snapshots as shallow, read-only volumes n constant time, without needing to clone the underlying snapshot data.

You can use the CephFS ROX shallow copy feature to efficiently back up CephFS-based volumes using VolSync when you back up these volumes with OADP 1.2 Data Mover.



Prerequisites

For snapshot functionality to be supported for your Kubernetes cluster, the Kubernetes version running in your cluster should be >= v1.17. We also need the snapshot controller deployed in your Kubernetes cluster along with csi-snapshotter sidecar container. Refer external-snapshotter for more information on these sidecar controllers. There should be a volumesnapshotclass object present in the cluster for snapshot request to be satisfied.

To install snapshot controller and CRD
./scripts/install-snapshot.sh install
To install from specific external-snapshotter version, you can leverage SNAPSHOT_VERSION variable, for example:

SNAPSHOT_VERSION="v5.0.1" ./scripts/install-snapshot.sh install
In the future, you can choose to cleanup by running
./scripts/install-snapshot.sh cleanup
NOTE: At present, there is a limit of 400 snapshots per cephFS filesystem. Also PVC cannot be deleted if it's having snapshots. Make sure all the snapshots on the PVC are deleted before you delete the PVC.




Usage
Provisioning a snapshot-backed volume from a volume snapshot
For provisioning new snapshot-backed volumes, following configuration must be set for storage class(es) and their PVCs respectively:

StorageClass:
Specify backingSnapshot: "true" parameter.
PersistentVolumeClaim:
Set storageClassName to point to your storage class with backing snapshots enabled.
Define spec.dataSource for your desired source volume snapshot.
Set spec.accessModes to ReadOnlyMany. This is the only access mode that is supported by this feature.
Mounting snapshots from pre-provisioned volumes
Steps for defining a PersistentVolume and PersistentVolumeClaim for pre-provisioned CephFS subvolumes are identical to those described in Static PVC with ceph-csi, except one additional parameter must be specified: backingSnapshotID. CephFS-CSI driver will retrieve the snapshot identified by the given ID from within the specified subvolume, and expose it to workloads in read-only mode. Volume access mode must be set to ReadOnlyMany.

Note that the snapshot retrieval is done by traversing <rootPath>/.snap and searching for a directory that contains backingSnapshotID value in its name. The specified snapshot ID does not necessarily need to be the complete directory name inside <rootPath>/.snap, however it must be complete enough to uniquely identify that directory.

Example:

$ ls .snap
_f279df14-6729-4342-b82f-166f45204233_1099511628283
_a364870e-6729-4342-b82f-166f45204233_1099635085072
f279df14-6729-4342-b82f-166f45204233 would be considered a valid value for backingSnapshotID volume parameter, whereas 6729-4342-b82f-166f45204233 would not, as it would be ambiguous.

If the given snapshot ID is ambiguous, or no such snapshot is found, mounting the PVC will fail with INVALID_ARGUMENT error code.